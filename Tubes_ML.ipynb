{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4slF/zZMMo1fS6LqP7ro+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AzisilhamK463/MachineLearning2023/blob/main/Tubes_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6UPfU3yeS33t",
        "outputId": "fd5aa5ba-0e4c-47d3-fa56-59043bb57938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imutils\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils.contours import sort_contours\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "PhkkOMt3TN4o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if (logs.get('accuracy') > 0.99):\n",
        "      print('\\nAkurasi mencapai 99%')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "7O6SocHhTN_l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder_path, target_size=(32, 32)):\n",
        "    data = []\n",
        "    labels = []\n",
        "    label_dict = {}\n",
        "    label_counter = 0\n",
        "\n",
        "    for label in os.listdir(folder_path):\n",
        "        label_dict[label_counter] = label\n",
        "        label_path = os.path.join(folder_path, label)\n",
        "        for image_file in os.listdir(label_path):\n",
        "            image_path = os.path.join(label_path, image_file)\n",
        "\n",
        "            try:\n",
        "                # Coba membaca gambar\n",
        "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if image is not None and not image.size == 0:\n",
        "                    # Resize gambar ke dimensi yang diinginkan\n",
        "                    image = cv.resize(image, target_size)\n",
        "                    data.append(image)\n",
        "                    labels.append(label_counter)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image {image_path}: {str(e)}\")\n",
        "\n",
        "        label_counter += 1\n",
        "\n",
        "    return np.array(data), np.array(labels), label_dict\n",
        "\n",
        "\n",
        "def train_ocr_model(folder_path, save_path = \"ml_model.h5\"):\n",
        "    # Memuat data dari folder huruf\n",
        "    data, labels, label_dict = load_data(folder_path)\n",
        "\n",
        "    # Membagi data menjadi train dan test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Mengonversi label menjadi one-hot encoding\n",
        "    y_train = to_categorical(y_train, num_classes=len(label_dict))\n",
        "    y_test = to_categorical(y_test, num_classes=len(label_dict))\n",
        "\n",
        "    # Membangun model CNN\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(len(label_dict), activation='softmax'))  # Jumlah kelas sesuai dengan jumlah huruf\n",
        "\n",
        "    # Kompilasi model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Praproses data untuk format yang diterima oleh model\n",
        "    X_train = X_train.reshape((X_train.shape[0], 32, 32, 1)).astype('float32') / 255\n",
        "    X_test = X_test.reshape((X_test.shape[0], 32, 32, 1)).astype('float32') / 255\n",
        "\n",
        "\n",
        "    # Augmentasi data menggunakan ImageDataGenerator\n",
        "    datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # Pelatihan model\n",
        "    history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=30, validation_data=(X_test, y_test), callbacks = [callbacks])\n",
        "\n",
        "    # Evaluasi model\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "    # Simpan model\n",
        "    model.save(save_path)\n",
        "    print(f'Model saved to {save_path}')"
      ],
      "metadata": {
        "id": "reBrirI5TOEC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ocr_model(\"/content/gdrive/MyDrive/Machine_Learning_2023/initiation_dataset\")"
      ],
      "metadata": {
        "id": "1mLIjWUZTg6V",
        "outputId": "6a19a606-10e8-4ef9-8787-e497b93c67f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "20/20 [==============================] - 4s 120ms/step - loss: 3.3812 - accuracy: 0.1132 - val_loss: 3.2071 - val_accuracy: 0.1401\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 2s 96ms/step - loss: 3.2266 - accuracy: 0.1292 - val_loss: 3.0793 - val_accuracy: 0.1401\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 3.0422 - accuracy: 0.1627 - val_loss: 2.7701 - val_accuracy: 0.2930\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 2.7696 - accuracy: 0.2775 - val_loss: 2.3771 - val_accuracy: 0.3949\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 2.4260 - accuracy: 0.3445 - val_loss: 2.0559 - val_accuracy: 0.4841\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 2.0292 - accuracy: 0.4370 - val_loss: 1.7872 - val_accuracy: 0.5096\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 1.8730 - accuracy: 0.4880 - val_loss: 1.5343 - val_accuracy: 0.6115\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 1.6242 - accuracy: 0.5470 - val_loss: 1.3259 - val_accuracy: 0.6688\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 1s 61ms/step - loss: 1.4616 - accuracy: 0.5726 - val_loss: 1.1073 - val_accuracy: 0.7707\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 1.1999 - accuracy: 0.6715 - val_loss: 1.0226 - val_accuracy: 0.7834\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 2s 96ms/step - loss: 1.1343 - accuracy: 0.6826 - val_loss: 0.9474 - val_accuracy: 0.8025\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 2s 94ms/step - loss: 1.1415 - accuracy: 0.6715 - val_loss: 0.9219 - val_accuracy: 0.8153\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 1.0178 - accuracy: 0.7033 - val_loss: 0.8342 - val_accuracy: 0.8408\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.9238 - accuracy: 0.7576 - val_loss: 0.7647 - val_accuracy: 0.8344\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 0.8039 - accuracy: 0.7831 - val_loss: 0.7898 - val_accuracy: 0.8217\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.7511 - accuracy: 0.8102 - val_loss: 0.7085 - val_accuracy: 0.8535\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.6563 - accuracy: 0.8182 - val_loss: 0.7109 - val_accuracy: 0.8408\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.6666 - accuracy: 0.8134 - val_loss: 0.6424 - val_accuracy: 0.8854\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 0.6207 - accuracy: 0.8166 - val_loss: 0.6455 - val_accuracy: 0.8726\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 0.5205 - accuracy: 0.8262 - val_loss: 0.6998 - val_accuracy: 0.8790\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 2s 98ms/step - loss: 0.5816 - accuracy: 0.8246 - val_loss: 0.6463 - val_accuracy: 0.8662\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 2s 91ms/step - loss: 0.5216 - accuracy: 0.8373 - val_loss: 0.6400 - val_accuracy: 0.8599\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.5428 - accuracy: 0.8293 - val_loss: 0.6349 - val_accuracy: 0.9045\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.5003 - accuracy: 0.8549 - val_loss: 0.6597 - val_accuracy: 0.9045\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.4418 - accuracy: 0.8676 - val_loss: 0.5688 - val_accuracy: 0.8981\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 0.4387 - accuracy: 0.8804 - val_loss: 0.6200 - val_accuracy: 0.9045\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.4009 - accuracy: 0.8772 - val_loss: 0.6519 - val_accuracy: 0.8917\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.3796 - accuracy: 0.8931 - val_loss: 0.5819 - val_accuracy: 0.8726\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.3936 - accuracy: 0.8708 - val_loss: 0.5831 - val_accuracy: 0.9108\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.3682 - accuracy: 0.9011 - val_loss: 0.5342 - val_accuracy: 0.9045\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5342 - accuracy: 0.9045\n",
            "Test accuracy: 0.9044585824012756\n",
            "Model saved to ml_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model.\n",
        "\n",
        "load_network = load_model('/content/ml_model.h5')\n",
        "load_network.summary()"
      ],
      "metadata": {
        "id": "nGB4L9pqTOIA",
        "outputId": "bca79335-9098-43b0-b399-978bb790bee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 36)                4644      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 318,500\n",
            "Trainable params: 318,500\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits = '0I23456789'\n",
        "letters = 'ABCDEFGHIJKLMNOPQRSTUVWZYZ'\n",
        "char_list = digits + letters\n",
        "char_list = [ch for ch in char_list]"
      ],
      "metadata": {
        "id": "3_ZGxL2IWmph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi preprocessing citra\n",
        "def preprocess_img(img):\n",
        "  blur = cv.GaussianBlur(img, (5,5), .5)\n",
        "  sharpened = cv.addWeighted(img, 1.5, blur,-0.5,0)\n",
        "  gray = cv.cvtColor(sharpened, cv.COLOR_BGR2GRAY)\n",
        "  _, thresh = cv.threshold(gray, 128, 255, cv.THRESH_BINARY_INV)\n",
        "  kernel = np.ones((1, 1), np.uint8)\n",
        "  closing = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations=1)\n",
        "  result = cv.dilate(closing, kernel, iterations=4)\n",
        "\n",
        "  return gray, result\n",
        "\n",
        "# Define function find contours for contour detection\n",
        "def find_contours(img):\n",
        "    conts = cv.findContours(img, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
        "    conts = imutils.grab_contours(conts)\n",
        "    conts = sort_contours(conts, method='left-to-right')[0]\n",
        "    return conts\n",
        "\n",
        "# Function to extract roi\n",
        "def extract_roi(img, x, y, w, h):\n",
        "    roi = img[y:y+h, x:x+w]\n",
        "    return roi\n",
        "\n",
        "# Function for thresholding\n",
        "def thresholding(img):\n",
        "    thresh = cv.threshold(img, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
        "    return thresh\n",
        "\n",
        "# Function for normalization\n",
        "def normalization(img):\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    return img\n",
        "\n",
        "# Function for resizing image\n",
        "def resize_img(img, w, h):\n",
        "    target_size = (32, 32)\n",
        "\n",
        "    if w > h:\n",
        "        new_h = int(target_size[1] * h / w)\n",
        "        resized = cv.resize(img, (target_size[0], new_h))\n",
        "    else:\n",
        "        new_w = int(target_size[0] * w / h)\n",
        "        resized = cv.resize(img, (new_w, target_size[1]))\n",
        "\n",
        "    (h, w) = resized.shape\n",
        "    dX = int(max(0, target_size[0] - w) / 2.0)\n",
        "    dY = int(max(0, target_size[1] - h) / 2.0)\n",
        "\n",
        "    filled = cv.copyMakeBorder(resized, top=dY, bottom=dY, right=dX, left=dX, borderType=cv.BORDER_CONSTANT, value=(0, 0, 0))\n",
        "    filled = cv.resize(filled, target_size)\n",
        "\n",
        "    return filled\n",
        "\n",
        "# Function to process box\n",
        "def process_box(gray, x, y, w, h):\n",
        "    roi = extract_roi(gray, x, y, w, h)\n",
        "    thresh = thresholding(roi)\n",
        "    resized = resize_img(thresh, w, h)\n",
        "    normalized = normalization(resized)\n",
        "\n",
        "    # show result\n",
        "    cv2_imshow(resized)\n",
        "\n",
        "    return (normalized, (x, y, w, h))\n",
        "\n",
        "# Function to process KTM image\n",
        "def process_ktm_image(image, model, char_list):\n",
        "    gray_ktm, prep_ktm = preprocess_img(image)\n",
        "    conts_border = find_contours(prep_ktm)\n",
        "\n",
        "    # Setup min/max width/hight for char\n",
        "    min_w, max_w = 5, 160\n",
        "    min_h, max_h = 36, 140\n",
        "    img_with_contour_ktm = image.copy()\n",
        "    for c in conts_border:\n",
        "        (x, y, w, h) = cv.boundingRect(c)\n",
        "        if(w >= min_w and w <= max_w) and (h >= min_h and h <= max_h):\n",
        "          roi = gray_ktm[y:y+h, x:x+w]\n",
        "          thresh = cv.threshold(roi, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
        "          cv.rectangle(img_with_contour_ktm, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
        "          # cv2_imshow(thresh) # check\n",
        "\n",
        "    cv2_imshow(img_with_contour_ktm)\n",
        "\n",
        "    # Extract and process characters\n",
        "    detected_char = []\n",
        "    for c in conts_border:\n",
        "        (x, y, w, h) = cv.boundingRect(c)\n",
        "        detected_char.append(process_box(gray_ktm, x, y, w, h))\n",
        "\n",
        "    # Get all char pixel\n",
        "    pixels = np.array([px[0] for px in detected_char], dtype='float32')\n",
        "\n",
        "    # Get all box for detected char\n",
        "    boxes = [box[1] for box in detected_char]\n",
        "\n",
        "    # Predict characters\n",
        "    preds = model.predict(pixels)\n",
        "\n",
        "    img_copy2 = image.copy()\n",
        "    for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
        "        i = np.argmax(pred)\n",
        "        char_detected = char_list[i]\n",
        "        cv.rectangle(img_copy2, (x, y), (x+w, y+h), (255,0,0), 2)\n",
        "        cv.putText(img_copy2, char_detected, (x - 10, y - 10), cv.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    cv2_imshow(img_copy2)"
      ],
      "metadata": {
        "id": "XbTfmNtbW9ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzAWm4tAXLpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}